apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: xgboost-pipeline
  annotations:
    cloud-pipelines.net/pipeline-editor: "true"
spec:
  entrypoint: XGBoost-pipeline
  templates:
    - name: Chicago-Taxi-Trips-dataset
      inputs:
        parameters:
          - name: Select
          - name: Where
          - name: Limit
          - name: Format
        artifacts: []
      outputs:
        parameters: []
        artifacts:
          - name: Table
            path: /tmp/outputs/Table/data
      container:
        name: main
        image: byrnedo/alpine-curl@sha256:548379d0a4a0c08b9e55d9d87a592b7d35d9ab3037f4936f5ccd09d0b625a342
        command:
          - sh
          - "-c"
          - |
            set -e -x -o pipefail
            output_path="$0"
            select="$1"
            where="$2"
            limit="$3"
            format="$4"
            mkdir -p "$(dirname "$output_path")"
            curl --get 'https://data.cityofchicago.org/resource/wrvz-psew.'"${format}" \
                --data-urlencode '$limit='"${limit}" \
                --data-urlencode '$where='"${where}" \
                --data-urlencode '$select='"${select}" \
                | tr -d '"' > "$output_path"  # Removing unneeded quotes around all numbers
          - "{{outputs.artifacts.Table.path}}"
          - "{{inputs.parameters.Select}}"
          - "{{inputs.parameters.Where}}"
          - "{{inputs.parameters.Limit}}"
          - "{{inputs.parameters.Format}}"
    - name: Xgboost-train
      inputs:
        parameters: []
        artifacts:
          - name: training_data
            path: /tmp/inputs/training_data/data
      outputs:
        parameters: []
        artifacts:
          - name: model
            path: /tmp/outputs/model/data
          - name: model_config
            path: /tmp/outputs/model_config/data
      container:
        name: main
        image: python:3.7
        command:
          - sh
          - "-c"
          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' --user) && "$0" "$@"
          - python3
          - "-u"
          - "-c"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def xgboost_train(
                training_data_path,  # Also supports LibSVM
                model_path,
                model_config_path,
                starting_model_path = None,

                label_column = 0,
                num_iterations = 10,
                booster_params = None,

                # Booster parameters
                objective = 'reg:squarederror',
                booster = 'gbtree',
                learning_rate = 0.3,
                min_split_loss = 0,
                max_depth = 6,
            ):
                '''Train an XGBoost model.

                Args:
                    training_data_path: Path for the training data in CSV format.
                    model_path: Output path for the trained model in binary XGBoost format.
                    model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.
                    starting_model_path: Path for the existing trained model to start from.
                    label_column: Column containing the label data.
                    num_boost_rounds: Number of boosting iterations.
                    booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html
                    objective: The learning task and the corresponding learning objective.
                        See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters
                        The most common values are:
                        "reg:squarederror" - Regression with squared loss (default).
                        "reg:logistic" - Logistic regression.
                        "binary:logistic" - Logistic regression for binary classification, output probability.
                        "binary:logitraw" - Logistic regression for binary classification, output score before logistic transformation
                        "rank:pairwise" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized
                        "rank:ndcg" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>
                '''
                import pandas
                import xgboost

                df = pandas.read_csv(
                    training_data_path,
                )

                training_data = xgboost.DMatrix(
                    data=df.drop(columns=[df.columns[label_column]]),
                    label=df[df.columns[label_column]],
                )

                booster_params = booster_params or {}
                booster_params.setdefault('objective', objective)
                booster_params.setdefault('booster', booster)
                booster_params.setdefault('learning_rate', learning_rate)
                booster_params.setdefault('min_split_loss', min_split_loss)
                booster_params.setdefault('max_depth', max_depth)

                starting_model = None
                if starting_model_path:
                    starting_model = xgboost.Booster(model_file=starting_model_path)

                model = xgboost.train(
                    params=booster_params,
                    dtrain=training_data,
                    num_boost_round=num_iterations,
                    xgb_model=starting_model
                )

                # Saving the model in binary format
                model.save_model(model_path)

                model_config_str = model.save_config()
                with open(model_config_path, 'w') as model_config_file:
                    model_config_file.write(model_config_str)

            import json
            import argparse
            _parser = argparse.ArgumentParser(prog='Xgboost train', description='Train an XGBoost model.\n\n    Args:\n        training_data_path: Path for the training data in CSV format.\n        model_path: Output path for the trained model in binary XGBoost format.\n        model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.\n        starting_model_path: Path for the existing trained model to start from.\n        label_column: Column containing the label data.\n        num_boost_rounds: Number of boosting iterations.\n        booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html\n        objective: The learning task and the corresponding learning objective.\n            See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n            The most common values are:\n            "reg:squarederror" - Regression with squared loss (default).\n            "reg:logistic" - Logistic regression.\n            "binary:logistic" - Logistic regression for binary classification, output probability.\n            "binary:logitraw" - Logistic regression for binary classification, output score before logistic transformation\n            "rank:pairwise" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\n            "rank:ndcg" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--training-data", dest="training_data_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--starting-model", dest="starting_model_path", type=str, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--label-column", dest="label_column", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--num-iterations", dest="num_iterations", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--booster-params", dest="booster_params", type=json.loads, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--objective", dest="objective", type=str, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--booster", dest="booster", type=str, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--learning-rate", dest="learning_rate", type=float, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--min-split-loss", dest="min_split_loss", type=float, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--max-depth", dest="max_depth", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--model-config", dest="model_config_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = xgboost_train(**_parsed_args)
        args:
          - "--training-data"
          - "{{inputs.artifacts.training_data.path}}"
          - "--model"
          - "{{outputs.artifacts.model.path}}"
          - "--model-config"
          - "{{outputs.artifacts.model_config.path}}"
    - name: Xgboost-predict
      inputs:
        parameters:
          - name: label_column
        artifacts:
          - name: data
            path: /tmp/inputs/data/data
          - name: model
            path: /tmp/inputs/model/data
      outputs:
        parameters: []
        artifacts:
          - name: predictions
            path: /tmp/outputs/predictions/data
      container:
        name: main
        image: python:3.7
        command:
          - sh
          - "-c"
          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'xgboost==1.1.1' 'pandas==1.0.5' --user) && "$0" "$@"
          - python3
          - "-u"
          - "-c"
          - |
            def _make_parent_dirs_and_return_path(file_path: str):
                import os
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return file_path

            def xgboost_predict(
                data_path,  # Also supports LibSVM
                model_path,
                predictions_path,
                label_column = None,
            ):
                '''Make predictions using a trained XGBoost model.

                Args:
                    data_path: Path for the feature data in CSV format.
                    model_path: Path for the trained model in binary XGBoost format.
                    predictions_path: Output path for the predictions.
                    label_column: Column containing the label data.

                Annotations:
                    author: Alexey Volkov <alexey.volkov@ark-kun.com>
                '''
                from pathlib import Path

                import numpy
                import pandas
                import xgboost

                df = pandas.read_csv(
                    data_path,
                )

                if label_column is not None:
                    df = df.drop(columns=[df.columns[label_column]])

                testing_data = xgboost.DMatrix(
                    data=df,
                )

                model = xgboost.Booster(model_file=model_path)

                predictions = model.predict(testing_data)

                Path(predictions_path).parent.mkdir(parents=True, exist_ok=True)
                numpy.savetxt(predictions_path, predictions)

            import argparse
            _parser = argparse.ArgumentParser(prog='Xgboost predict', description='Make predictions using a trained XGBoost model.\n\n    Args:\n        data_path: Path for the feature data in CSV format.\n        model_path: Path for the trained model in binary XGBoost format.\n        predictions_path: Output path for the predictions.\n        label_column: Column containing the label data.\n\n    Annotations:\n        author: Alexey Volkov <alexey.volkov@ark-kun.com>')
            _parser.add_argument("--data", dest="data_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--model", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
            _parser.add_argument("--label-column", dest="label_column", type=int, required=False, default=argparse.SUPPRESS)
            _parser.add_argument("--predictions", dest="predictions_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
            _parsed_args = vars(_parser.parse_args())

            _outputs = xgboost_predict(**_parsed_args)
        args:
          - "--data"
          - "{{inputs.artifacts.data.path}}"
          - "--model"
          - "{{inputs.artifacts.model.path}}"
          - "--label-column"
          - "{{inputs.parameters.label_column}}"
          - "--predictions"
          - "{{outputs.artifacts.predictions.path}}"
    - name: XGBoost-pipeline
      inputs:
        parameters: []
        artifacts: []
      outputs:
        artifacts: []
      dag:
        tasks:
          - name: dataset
            template: Chicago-Taxi-Trips-dataset
            arguments:
              parameters:
                - name: Select
                  value: tips,trip_seconds,trip_miles,pickup_community_area,dropoff_community_area,fare,tolls,extras,trip_total
                - name: Where
                  value: trip_start_timestamp >= "2019-01-01" AND trip_start_timestamp < "2019-02-01"
                - name: Limit
                  value: "1000"
                - name: Format
                  value: csv
              artifacts: []
            dependencies: []
          - name: train
            template: Xgboost-train
            arguments:
              parameters: []
              artifacts:
                - name: training_data
                  from: "{{tasks.dataset.outputs.artifacts.Table}}"
            dependencies:
              - dataset
          - name: predict
            template: Xgboost-predict
            arguments:
              parameters:
                - name: label_column
                  value: "0"
              artifacts:
                - name: data
                  from: "{{tasks.dataset.outputs.artifacts.Table}}"
                - name: model
                  from: "{{tasks.train.outputs.artifacts.model}}"
            dependencies:
              - dataset
              - train
  arguments:
    parameters: []
    artifacts: []
